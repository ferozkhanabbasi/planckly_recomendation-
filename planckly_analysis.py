# -*- coding: utf-8 -*-
"""Planckly Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1km545g-a1cS9vugAIlrnALna9yreNcJ1
"""



import turicreate 
import pandas as pd
#from sklearn.cross_validation import train_test_split
import numpy as np
import datetime

import os
from sklearn import preprocessing
import requests 
import seaborn as sns
import matplotlib.pyplot as plt

baskets_df = pd.read_csv("baskets.csv")
transaction_df = pd.read_csv("transactions.csv")
branches_df=pd.read_csv("branches.csv")
users_df=pd.read_csv("users.csv")
stores_df=pd.read_csv("stores.csv")
categories_df=pd.read_csv("categories.csv")

transaction_df = transaction_df.drop(['promotion_id', 'tax_id', 'seat_number', 'sequence' ],axis=1)

transaction_df['updated_day'] = pd.DatetimeIndex(transaction_df['updated_at']).dayofweek
transaction_df['updated_time'] = pd.DatetimeIndex(transaction_df['updated_at']).time
transaction_df[['updated_hour','updated_minutes','updated_seconds']] = transaction_df['updated_time'].apply(lambda x:pd.Series(x.strftime("%H,%M,%S").split(',')))
transaction_df = transaction_df.drop(['created_at','updated_at','updated_time'],axis=1)

baskets_df = baskets_df.drop(['gross','discount','tax_id','total_charity','total_tax','checked_by','notification_seen', 'order_id','net','status','voucher_id','gift_aid','gift_aid_postcode','roundoff','amount_to_charity','charity_id','checked_at','order_type','table_number','accept_status','buyer_comments','seller_comments','group_id'],axis=1)

baskets_df['day_months']= pd.DatetimeIndex(baskets_df['updated_at']).month
baskets_df['updated_day']= pd.DatetimeIndex(baskets_df['updated_at']).dayofweek
baskets_df['updated_time'] = pd.DatetimeIndex(baskets_df['updated_at']).time
baskets_df[['updated_hour','updated_minutes','updated_seconds']] = baskets_df['updated_time'].apply(lambda x:pd.Series(x.strftime("%H,%M,%S").split(',')))
baskets_df = baskets_df.drop(['created_at','updated_at','updated_time'],axis=1)

branches_df = branches_df.drop(['branch_token','name', 'map_image', 'town', 'post_code', 'currency_symbol', 'credit_allowed', 'is_tax_included', 'stored_on', 'website', 'email', 'phone', 'description', 'created_at', 'updated_at'], axis=1)

# df['total_items'].fillna(df['total_items'].mean(),inplace=True)
# df.isnull().sum()|

baskets_df['updated_hour']=baskets_df['updated_hour'].astype(float)
baskets_df['branch_id']=baskets_df['branch_id'].astype('int64',copy=False)

branches_df['id']=branches_df['id'].astype('int64',copy=False)
transaction_df['updated_hour'] = transaction_df['updated_hour'].astype(float)

transaction_SFrame = turicreate.SFrame(transaction_df)
baskets_SFrame = turicreate.SFrame(baskets_df)
most_popular_data = baskets_SFrame.join(right=transaction_SFrame,on={'id':'basket_id'},how='inner').sort(['id'], ascending=True)
del most_popular_data['updated_hour.1']
del most_popular_data['day_months']
del most_popular_data['updated_minutes.1']
del most_popular_data['updated_minutes']
del most_popular_data['updated_day.1']
del most_popular_data['updated_seconds.1']
del most_popular_data['updated_seconds']
del most_popular_data['final_price']
del most_popular_data['total_price']
del most_popular_data['discounted_price']

most_popular_data.print_rows(num_rows=4)

popularity_model = turicreate.item_similarity_recommender.create(most_popular_data, user_id='user_id', item_id='item', target='updated_hour')

recommend = popularity_model.recommend(users=[804],k=5)
recommend.print_rows(num_rows=55)

recommend.export_json('similarities.json', orient='records')

recommend_json = pd.read_json('similarities.json')

popularity_model1 = turicreate.recommender.create(most_popular_data, user_id='user_id', item_id ='item', target='updated_hour')

recommend1 = popularity_model1.recommend(users=[147],k=5)
recommend1.print_rows(num_rows=55)

popularity_model2 = turicreate.recommender.item_similarity_recommender.create(most_popular_data, user_id='user_id', item_id ='item', target='updated_hour')

recommend2 = popularity_model2.recommend(users=[804],k=5)
recommend2.print_rows(num_rows=55)

#m = turicreate.factorization_recommender.create(sf)
similarities_hours = turicreate.factorization_recommender.create(most_popular_data,item_id = 'item' ,target='updated_hour')
similarities_days = turicreate.factorization_recommender.create(most_popular_data,item_id = 'item' ,target='updated_day')
similarities_location = turicreate.factorization_recommender.create(most_popular_data,item_id ='item' ,target='branch_id')

similar_users_of_hours = similarities_hours.get_similar_users(users=[147,804],k=5)
similar_users_of_days = similarities_days.get_similar_users(users=[147,804],k=5)
similar_users_of_location = similarities_hours.get_similar_users(users=[147,804],k=5)

similar_users_of_location.export_json('users.json', orient='records')
users_json = pd.read_json('users.json')

similar_items_of_hours = similarities_hours.get_similar_items(items=[33],k=5 )
similar_items_of_days = similarities_days.get_similar_items(items=[33],k=5 )


from flask import jsonify
import socket
print(socket.gethostbyname(socket.getfqdn(socket.gethostname())))

from flask import Flask
app = Flask(__name__)


@app.route('/similarities/<userID>/')
def itemSimilarities(userID):
  recommendations = popularity_model.recommend(users=[userID],k=5)
  recommendations.export_json('similarity.json', orient='records')
  recommend_json = pd.read_json('similarity.json')
  similar_items_json = recommend_json.to_json()
  return similar_items_json

   
@app.route('/mydata')
def mydata():
    m = users_json.to_json()
    return m
@app.route("/")
def hello():
    l = y.to_json()
    return l

import threading
threading.Thread(target=app.run, kwargs={'host':'0.0.0.0','port':101}).start()

import requests,json
response = requests.get("http://172.28.0.2:101/similarities/804/")
json_data = json.loads(response.text)
print(json_data)
